{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "#import pillow\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Images whose corners were found\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "#### CAMERA CALIBRATION ####\n",
    "############################\n",
    "\n",
    "## Initialization ##\n",
    "\n",
    "nx = 9 # no. of inside corners in x\n",
    "ny = 6 # no. of inside corners in y\n",
    "\n",
    "cal_img_list = []\n",
    "undistorted_img = []\n",
    "warped_img = []\n",
    "\n",
    "# Make a list of calibration images\n",
    "raw_img_dir = './camera_cal/calibration*.jpg'\n",
    "for fname in glob.glob(raw_img_dir):\n",
    "    image = cv2.imread(fname)\n",
    "    cal_img_list.append(image)\n",
    "\n",
    "cal_img_list = np.array(cal_img_list)    \n",
    "    \n",
    "# Array to store object points and image points from all the images\n",
    "object_points = [] #3D points in real world space\n",
    "image_points = [] #2D points in image plane\n",
    "\n",
    "# prespare object points\n",
    "objpts = np.zeros((ny*nx,3),np.float32) \n",
    "objpts[:,:2] = np.mgrid[0:6,0:9].T.reshape(-1,2) #list down x & y co-ordinates\n",
    "#print(objpts[:,:2])\n",
    "\n",
    "## Find Image & Object Points ##\n",
    "\n",
    "for img in cal_img_list:\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (ny, nx), None)\n",
    "    if ret == True:\n",
    "        image_points.append(corners)\n",
    "        object_points.append(objpts)\n",
    "        undistorted_img.append(img)\n",
    "    else:\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "        #print('Corners not found!')\n",
    "        pass\n",
    "        \n",
    "\n",
    "print('No. of Images whose corners were found')\n",
    "print(len(undistorted_img))\n",
    "\n",
    "# Calibrate Camera\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(object_points, image_points, gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test Undistortion ##\n",
    "\n",
    "def plot(img1, img2, label1, label2, fname):\n",
    "    f, (p1, p2) = plt.subplots(1,2, figsize=(20,12))\n",
    "    p1.imshow(img1)\n",
    "    p1.set_title(label1, fontsize=25)\n",
    "    p2.imshow(img2, cmap='gray')\n",
    "    p2.set_title(label2, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n",
    "#     f.savefig('output_images/'+fname+'.png') #save last pic for report\n",
    "\n",
    "for a in range(0,len(undistorted_img)):\n",
    "    test_img1 = undistorted_img[a]\n",
    "    undst1 = cv2.undistort(test_img1, mtx, dist, None, mtx)\n",
    "    #plot(test_img1, undst1, 'Original', 'Undistorted')\n",
    "\n",
    "#f.savefig('output_images/Test_Undistorted.png') #save last pic for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Perspective Transform ##\n",
    "\n",
    "def corners_warp(img, nx, ny):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray,(nx,ny),None)\n",
    "    img_size = gray.shape\n",
    "    offset = 100\n",
    "    if ret == True:\n",
    "        cv2.drawChessboardCorners(img, (nx,ny),corners,ret)\n",
    "        src = np.float32([corners[0], corners[nx-1], corners[-1], corners[-nx]])\n",
    "        dest = np.float32([[offset,offset],[img_size[1]-offset,offset],\n",
    "                           [img_size[1]-offset,img_size[0]-offset],[offset,img_size[0]-offset]])\n",
    "        M = cv2.getPerspectiveTransform(src,dest)\n",
    "        warped = cv2.warpPerspective(img, M, (img_size[1], img_size[0]), flags=cv2.INTER_LINEAR)\n",
    "        return warped, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Test Undistortion & Warping ##\n",
    "\n",
    "for a in range(0, len(undistorted_img)):\n",
    "    test_img2 = undistorted_img[a]\n",
    "    undst2 = cv2.undistort(test_img2,mtx,dist,None,mtx)\n",
    "    if a is not 10:\n",
    "        top_down, perspective_M = corners_warp(undst2, nx, ny)\n",
    "        #plot(test_img2, top_down, 'Original', 'Undistorted')\n",
    "\n",
    "#f.savefig('output_images/Test_Undistortion_Warping.png') #save last pic for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################\n",
    "#### LANE FINDING ####\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Gradient & Color Transform ##\n",
    "\n",
    "def abs_sobel_thresh(img, orient, thresh):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    if orient == 'x':\n",
    "        sobel = cv2.Sobel(gray,cv2.CV_64F,1,0)\n",
    "    elif orient == 'y':\n",
    "        sobel = cv2.Sobel(gray,cv2.CV_64F,0,1)\n",
    "    else:\n",
    "        print(\"Select Appropriate Orientation!\")\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    Sxbinary = np.zeros_like(scaled_sobel)\n",
    "    Sxbinary[(scaled_sobel >= thresh[0]) & (scaled_sobel<= thresh[1])]=1\n",
    "    return Sxbinary\n",
    "    \n",
    "def mag_threshold(img, sobel_kernel, mag_thresh):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel )\n",
    "    sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    abs_sobelxy = np.sqrt(sobelx**2+sobely**2)\n",
    "    scaled_sobel = np.uint8(255*abs_sobelxy/np.max(abs_sobelxy))\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel > mag_thresh[0]) & (scaled_sobel < mag_thresh[1])]=1\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(img, sobel_kernel, dir_thresh):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    abs_sobelx=np.absolute(sobelx)\n",
    "    abs_sobely=np.absolute(sobely)\n",
    "    dir_sobel=np.arctan2(abs_sobely,abs_sobelx)\n",
    "    binary_output=np.zeros_like(dir_sobel)\n",
    "    binary_output[(dir_sobel>=dir_thresh[0]) & (dir_sobel<=dir_thresh[1])]=1\n",
    "    return binary_output\n",
    "\n",
    "def hls_select(img, threshS):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S>threshS[0]) & (S<=threshS[1])] = 1\n",
    "    return binary_output\n",
    "\n",
    "def lab_bthresh(img, thresh):\n",
    "    # 1) Convert to LAB color space\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab)\n",
    "    lab_b = lab[:,:,2]\n",
    "    # don't normalize if there are no yellows in the image\n",
    "    if np.max(lab_b) > 175:\n",
    "        lab_b = lab_b*(255/np.max(lab_b))\n",
    "    # 2) Apply a threshold to the L channel\n",
    "    binary_output = np.zeros_like(lab_b)\n",
    "    binary_output[((lab_b > thresh[0]) & (lab_b <= thresh[1]))] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "# Initialization #\n",
    "\n",
    "# test_img = cv2.imread('./test_images/test5.jpg')\n",
    "# undst = cv2.undistort(test_img, mtx, dist, None, mtx)\n",
    "# # plot(test_img, undst, 'Original', 'Undistorted', 'Undistorted Image')\n",
    "\n",
    "# ksize = 15\n",
    "\n",
    "# gradx = abs_sobel_thresh(undst, orient='x', thresh=(20,255))\n",
    "# # plot(test_img, gradx, 'Original', 'Gradient X Threshold', 'Gradient X Threshold')\n",
    "\n",
    "# grady = abs_sobel_thresh(undst, orient='y', thresh=(40,255))\n",
    "# # plot(test_img, grady, 'Original', 'Gradient Y Threshold', 'Gradient Y Threshold')\n",
    "\n",
    "# mag_binary = mag_threshold(undst, sobel_kernel=ksize, mag_thresh=(60,255))\n",
    "# # plot(test_img, mag_binary, 'Original', 'Gradient Mag_Threshold', 'Gradient Mag_Threshold')\n",
    "\n",
    "# dir_binary = dir_threshold(undst, sobel_kernel=ksize, dir_thresh=(0.5,1.3))\n",
    "# # plot(test_img, dir_binary, 'Original', 'Gradient Dir_Threshold', 'Gradient Dir_Threshold')\n",
    "\n",
    "# combined_gradient = np.zeros_like(dir_binary)\n",
    "# combined_gradient[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "# # plot(test_img, combined_gradient, 'Original', 'Final Grayscale', 'Final Grayscale')\n",
    "\n",
    "# SL_Filter = hls_select(test_img, threshS=(160,255))\n",
    "# # plot(test_img, SL_Filter, 'Original', 'HLS SL Color Filter', 'HLS SL Color Filter')\n",
    "\n",
    "# B_Filter = lab_bthresh(test_img, thresh=(0,100))\n",
    "# # plot(test_img, B_Filter, 'Original', 'LAB B Color Filter', 'LAB B Color Filter')\n",
    "\n",
    "# color_filters = np.zeros_like(SL_Filter)\n",
    "# color_filters[(SL_Filter == 1) | (B_Filter == 1)] = 1\n",
    "# # plot(test_img, color_filters, 'Original', 'Combined Color Filters', 'Combined Color Filters')\n",
    "\n",
    "# Final_Grad_Image = np.zeros_like(color_filters)\n",
    "# Final_Grad_Image[(color_filters == 1) | (combined_gradient == 1)] = 1\n",
    "# # plot(test_img, Final_Grad_Image, 'Original', 'Final Gradient Image', 'Final Gradient Image')\n",
    "\n",
    "# # Stack each channel to view their individual contributions in green and blue respectively\n",
    "# # This returns a stack of the two binary images, whose components you can see as different colors\n",
    "# color_binary = np.zeros_like(combined_gradient)\n",
    "# color_binary = np.uint8(np.dstack(( np.zeros_like(combined_gradient), combined_gradient, color_filters)) * 255)\n",
    "# # plot(color_binary, Final_Grad_Image, 'Stacked Thresholds', 'Final Image', 'Stacked Thresholds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Warping the Lanes ##\n",
    "\n",
    "def plot(img1, img2, label1, label2, fname):\n",
    "    f, (p1, p2) = plt.subplots(1,2, figsize=(20,12))\n",
    "    p1.imshow(img1, cmap='gray')\n",
    "    p1.set_title(label1, fontsize=25)\n",
    "    p2.imshow(img2, cmap='gray')\n",
    "    p2.set_title(label2, fontsize=25)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "    plt.show()\n",
    "#     f.savefig('output_images/'+fname+'.png') #save last pic for report\n",
    "\n",
    "def warping(img):\n",
    "    img_size = img.shape\n",
    "    src = np.float32(np.array([[200,720],[600,450],[700,450],[1100,720]]))\n",
    "    dest = np.float32(np.array([[350,720],[350,0],[950,0],[950,720]]))\n",
    "    pt1 = np.float32(np.array([[0,720],[0,0],[200,0],[200,720]]))\n",
    "    pt2 = np.float32(np.array([[1100,720],[1100,0],[1280,0],[1280,720]]))\n",
    "    M = cv2.getPerspectiveTransform(src,dest)\n",
    "    Minv = cv2.getPerspectiveTransform(dest, src)\n",
    "    warped = cv2.warpPerspective(img, M, (img_size[1], img_size[0]), flags=cv2.INTER_LINEAR)\n",
    "    cv2.fillPoly(warped, np.int_([pt1]), (0,255))\n",
    "    cv2.fillPoly(warped, np.int_([pt2]), (0,255))\n",
    "    return warped, M, Minv\n",
    "    \n",
    "    \n",
    "# base_img = np.copy(Final_Grad_Image)\n",
    "# warped_img, M, Minv = warping(base_img)\n",
    "# # plot(base_img, warped_img, 'Original', 'Warped', 'Warped_Image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding Lines ##\n",
    "def DrawHisto(img):\n",
    "    histo = np.sum(img[img.shape[0]//2:,:], axis=0)\n",
    "#     f = plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(histo)\n",
    "#     plt.show()\n",
    "#     f.savefig('output_images/Histogram.png') #save last pic for report\n",
    "    return histo\n",
    "\n",
    "def DrawSlidingWindow(warped_img, histogram):\n",
    "    out_img = np.dstack((warped_img, warped_img, warped_img))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(warped_img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = warped_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = warped_img.shape[0] - (window+1)*window_height\n",
    "        win_y_high = warped_img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),\n",
    "        (0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    ploty = np.linspace(0, warped_img.shape[0]-1, warped_img.shape[0] )\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "  \n",
    "    return left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy, ploty, margin\n",
    "\n",
    "def Visualization(warped_img, left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy, ploty, margin):\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((warped_img, warped_img, warped_img))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    \n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    return out_img, result\n",
    "\n",
    "# histogram = DrawHisto(warped_img)\n",
    "\n",
    "# left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy, ploty, margin = DrawSlidingWindow(warped_img, histogram)\n",
    "# RB_lane_lines, vis_lane_lines = Visualization(warped_img, left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy, ploty, margin)\n",
    "\n",
    "# f = plt.figure(figsize=(10,6))\n",
    "# plt.imshow(vis_lane_lines)\n",
    "# plt.plot(left_fitx, ploty, color='yellow')\n",
    "# plt.plot(right_fitx, ploty, color='yellow')\n",
    "# plt.xlim(0, 1280)\n",
    "# plt.ylim(720, 0)\n",
    "# plt.show()\n",
    "# # f.savefig('output_images/Sliding_Window_Visualization.png') #save last pic for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding Radius of Curvature ##\n",
    "\n",
    "def FindROC(left_fitx, right_fitx, ploty):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/600 # meters per pixel in x dimension\n",
    "\n",
    "    y_eval = np.max(ploty)\n",
    "\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(ploty*ym_per_pix, left_fitx*xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, right_fitx*xm_per_pix, 2)\n",
    "\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "      \n",
    "    xMax = img.shape[1]*xm_per_pix\n",
    "    yMax = img.shape[0]*ym_per_pix\n",
    "    vehicleCenter = xMax / 2\n",
    "    lineLeft = left_fit_cr[0]*yMax**2 + left_fit_cr[1]*yMax + left_fit_cr[2]\n",
    "    lineRight = right_fit_cr[0]*yMax**2 + right_fit_cr[1]*yMax + right_fit_cr[2]\n",
    "    lineMiddle = lineLeft + (lineRight - lineLeft)/2\n",
    "    diffFromVehicle = vehicleCenter - lineMiddle\n",
    "    \n",
    "    return left_curverad, right_curverad, left_fit_cr, right_fit_cr, diffFromVehicle\n",
    "\n",
    "# left_curverad, right_curverad, left_fit_cr, right_fit_cr, diffFromVehicle = FindROC(left_fitx, right_fitx, ploty)\n",
    "\n",
    "# print('Left Lane ROC: ', left_curverad/1000, 'km')\n",
    "# print('Right Lane ROC: ', right_curverad/1000, 'km')\n",
    "# print('Vehicle Deviation from center: ', diffFromVehicle, 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unwarping The Lanes & Lane Area ##\n",
    "\n",
    "def DisplayPanel(undst, RB_lane_lines, vis_lane_lines, left_fitx, right_fitx, ploty, curverad, diffFromVehicle, Minv):\n",
    "    # Initialization\n",
    "    lane_area = np.zeros_like(RB_lane_lines)\n",
    "\n",
    "    # Collecting left and Right points to find Lane Area\n",
    "    left_inner_pts = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    right_inner_pts = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((left_inner_pts, right_inner_pts))\n",
    "\n",
    "    cv2.fillPoly(lane_area, np.int_([pts]), (0,255,0))\n",
    "\n",
    "    # Unwarping Colored Lane Lines and Lane Area\n",
    "    unwarped_lane_area = cv2.warpPerspective(lane_area, Minv, (undst.shape[1], undst.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    unwarped_lane_lines = cv2.warpPerspective(RB_lane_lines, Minv, (undst.shape[1], undst.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    lane_lines = cv2.addWeighted(unwarped_lane_lines,1,unwarped_lane_area,0.3,0)\n",
    "\n",
    "    # Final Output Panel Image Generation\n",
    "    final_output = cv2.add(undst, lane_lines)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    text1 = ('Radius of Curvature : {:.4f} km'.format(curverad/1000))            \n",
    "    if diffFromVehicle > 0:\n",
    "        text2 = '{:.2f} m right'.format(diffFromVehicle)\n",
    "    else:\n",
    "        text2 = '{:.2f} m left'.format(-diffFromVehicle)\n",
    "    cv2.putText(final_output, text1, (50, 50), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(final_output, 'Vehicle is {} of center'.format(text2), (50, 100), font, 0.8, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    white = [255,255,255]     #---Color of the border---\n",
    "    undst = cv2.copyMakeBorder(undst,5,5,5,5,cv2.BORDER_CONSTANT,value=white)\n",
    "    final_output = cv2.copyMakeBorder(final_output,5,5,5,5,cv2.BORDER_CONSTANT,value=white)\n",
    "    vis_lane_lines = cv2.copyMakeBorder(vis_lane_lines,5,5,5,5,cv2.BORDER_CONSTANT,value=white)\n",
    "    lane_lines = cv2.copyMakeBorder(lane_lines,5,5,5,5,cv2.BORDER_CONSTANT,value=white)\n",
    "    \n",
    "    \n",
    "    horizontal1 = np.hstack((undst, final_output))\n",
    "    horizontal2 = np.hstack((vis_lane_lines, lane_lines))\n",
    "    Panel = np.vstack((horizontal1, horizontal2))\n",
    "    return Panel\n",
    "\n",
    "# Panel = DisplayPanel(undst, RB_lane_lines, vis_lane_lines, left_fitx, right_fitx, ploty, left_curverad, diffFromVehicle, Minv)\n",
    "\n",
    "# f = plt.figure(figsize=(20, 20))\n",
    "# plt.imshow(Panel)\n",
    "# plt.show()\n",
    "# # f.savefig('output_images/Panel_Output.png') #save last pic for report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################\n",
    "#### PIPELINE FOR ADVANCE LANE FINDING ####\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def meanLaneWidth(left_fitx, right_fitx, ploty):\n",
    "    # calcualtes averae horizontal distance\n",
    "    # between left and right lane lines\n",
    "    dataLength = ploty.size\n",
    "    intervalSize = dataLength//50\n",
    "    laneWidth = []\n",
    "    for i in range(0,dataLength, intervalSize):\n",
    "        dist = right_fitx[i] - left_fitx[i]\n",
    "        laneWidth.append(dist)\n",
    "    \n",
    "    laneWidth = np.array(laneWidth)\n",
    "    meanLaneWidth = np.mean(laneWidth)\n",
    "    stddevLaneWidth = np.std(laneWidth)\n",
    "    \n",
    "    return meanLaneWidth, stddevLaneWidth\n",
    "\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.left_fitx = None\n",
    "        self.right_fitx = None\n",
    "        self.left_fit_cr = None\n",
    "        self.right_fit_cr = None\n",
    "        self.radius_of_curvature = None        \n",
    "        self.line_base_pos = None\n",
    "        self.left_curverad = None\n",
    "        self.right_curverad = None\n",
    "        self.detected = False\n",
    "        self.dominantLine = False\n",
    "        \n",
    "leftLane = Line()\n",
    "rightLane = Line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ALF_Pipeline(img):\n",
    "    ksize = 15\n",
    "    lwMeandev = 0.1 # percent\n",
    "    lwStddev = 5 # pixels\n",
    "    \n",
    "    # Gradient & Color Threshold Step\n",
    "    undst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    gradx = abs_sobel_thresh(undst, orient='x', thresh=(20,255))\n",
    "    grady = abs_sobel_thresh(undst, orient='y', thresh=(40,255))\n",
    "    mag_binary = mag_threshold(undst, sobel_kernel=ksize, mag_thresh=(60,255))\n",
    "    dir_binary = dir_threshold(undst, sobel_kernel=ksize, dir_thresh=(0.5,1.3))\n",
    "    combined_gradient = np.zeros_like(dir_binary)\n",
    "    combined_gradient[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    SL_Filter = hls_select(undst, threshS=(160,255))\n",
    "    B_Filter = lab_bthresh(undst, thresh=(0,100))\n",
    "    color_filters = np.zeros_like(SL_Filter)\n",
    "    color_filters[(SL_Filter == 1) | (B_Filter == 1)] = 1\n",
    "    Final_Grad_Image = np.zeros_like(color_filters)\n",
    "    Final_Grad_Image[(color_filters == 1) | (combined_gradient == 1)] = 1\n",
    "    \n",
    "    # Warping Image\n",
    "    warped_img, M, Minv = warping(Final_Grad_Image)\n",
    "    if ((leftLane.detected == False) or (rightLane.detected == False)): \n",
    "\n",
    "        histogram = DrawHisto(warped_img)\n",
    "        # Find the peak of the left and right halves of the histogram\n",
    "        # These will be the starting point for the left and right lines\n",
    "        midpoint = np.int(histogram.shape[0]/2)\n",
    "        leftx_base = np.argmax(histogram[:midpoint])\n",
    "        rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "        \n",
    "        # choose the line with more data points for Radius of Curv. display\n",
    "        if histogram[leftx_base] >= histogram[rightx_base]:\n",
    "            leftLane.dominantLine = True\n",
    "        else:\n",
    "            leftLane.dominantLine = False\n",
    "    \n",
    "    left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy, ploty, margin = DrawSlidingWindow(warped_img, histogram)\n",
    "    mean, stddev = meanLaneWidth(left_fitx, right_fitx, ploty)\n",
    "    left_curverad, right_curverad, left_fit_cr, right_fit_cr, diffFromVehicle = FindROC(left_fitx, right_fitx, ploty)  \n",
    "    \n",
    "    if (leftLane.dominantLine == True):\n",
    "            curverad = left_curverad\n",
    "    else:\n",
    "            curverad = right_curverad\n",
    "            \n",
    "    if ((abs(mean - 600) < lwMeandev*600)  and (stddev < lwStddev)):\n",
    "        left_fitx = leftLane.left_fitx\n",
    "        left_fit_cr = leftLane.left_fit_cr\n",
    "        right_fitx = rightLane.right_fitx\n",
    "        right_fit_cr = rightLane.right_fit_cr\n",
    "    else:\n",
    "        leftLane.left_fitx = left_fitx\n",
    "        leftLane.left_fit_cr = left_fit_cr\n",
    "        rightLane.right_fitx = right_fitx\n",
    "        rightLane.right_fit_cr = right_fit_cr\n",
    "\n",
    "    \n",
    "    RB_lane_lines, vis_lane_lines = Visualization(warped_img, left_fitx, right_fitx, left_lane_inds, right_lane_inds, nonzerox, nonzeroy, ploty, margin)\n",
    "    Panel = DisplayPanel(undst, RB_lane_lines, vis_lane_lines, left_fitx, right_fitx, ploty, curverad, diffFromVehicle, Minv)\n",
    "    return Panel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./output_videos/project_video_with_lanes_2.mp4\n",
      "[MoviePy] Writing video ./output_videos/project_video_with_lanes_2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████▉| 1260/1261 [07:42<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./output_videos/project_video_with_lanes_2.mp4 \n",
      "\n",
      "Wall time: 7min 44s\n"
     ]
    }
   ],
   "source": [
    "white_output = './output_videos/project_video_with_lanes_2.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "##clip1 = VideoFileClip(\"test_videos/solidWhiteRight.mp4\").subclip(0,5)\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "white_clip = clip1.fl_image(ALF_Pipeline) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
